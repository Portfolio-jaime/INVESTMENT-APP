# Arquitectura del Sistema TRII Platform

## ğŸ—ï¸ VisiÃ³n General

TRII Platform estÃ¡ diseÃ±ada siguiendo principios de **arquitectura de microservicios**, **domain-driven design** y **event-driven architecture** para garantizar escalabilidad, mantenibilidad y alta disponibilidad.

## ğŸ¯ Principios ArquitectÃ³nicos

### 1. **Separation of Concerns**
- Cada microservicio tiene una responsabilidad especÃ­fica
- Boundaries claros entre dominios de negocio
- APIs bien definidas entre servicios

### 2. **Event-Driven Architecture**
- ComunicaciÃ³n asÃ­ncrona via RabbitMQ
- Event sourcing para auditabilidad
- CQRS para separar lecturas y escrituras

### 3. **Cloud-Native**
- ContainerizaciÃ³n con Docker
- OrquestaciÃ³n con Kubernetes  
- Observabilidad integrada
- Auto-scaling horizontal

## ğŸ›ï¸ Diagrama de Arquitectura de Alto Nivel

```mermaid
graph TB
    subgraph "ğŸŒ External"
        USER[ğŸ‘¥ Users]
        MARKET[ğŸ“ˆ Market APIs]
        NEWS[ğŸ“° News APIs]
    end

    subgraph "ğŸ›¡ï¸ Edge Layer"
        CDN[ğŸŒ CloudFlare CDN]
        WAF[ğŸ”’ WAF]
        LB[âš–ï¸ Load Balancer]
    end

    subgraph "ğŸšª API Gateway"
        KONG[ğŸ¦ Kong Gateway]
        AUTH[ğŸ” Auth Service]
        RATE[ğŸš¦ Rate Limiting]
    end

    subgraph "ğŸ¯ Frontend Layer"
        WEB[ğŸ’» React Web App]
        MOBILE[ğŸ“± React Native]
        DESKTOP[ğŸ–¥ï¸ Electron App]
    end

    subgraph "âš™ï¸ Core Services"
        MARKET_SVC[ğŸ“Š Market Data Service]
        ANALYSIS_SVC[ğŸ” Analysis Engine]
        ML_SVC[ğŸ¤– ML Prediction Service]
        PORTFOLIO_SVC[ğŸ’¼ Portfolio Manager]
        NOTIFICATION_SVC[ğŸ“¢ Notification Service]
        USER_SVC[ğŸ‘¤ User Service]
    end

    subgraph "ğŸ’¾ Data Layer"
        PG[(ğŸ—„ï¸ PostgreSQL)]
        TS[(ğŸ“ˆ TimescaleDB)]
        REDIS[(âš¡ Redis)]
        S3[(â˜ï¸ Object Storage)]
    end

    subgraph "ğŸ“¡ Message Layer"
        RABBIT[ğŸ° RabbitMQ]
        KAFKA[ğŸ“¨ Apache Kafka]
    end

    subgraph "ğŸ“Š Observability"
        PROM[ğŸ“ˆ Prometheus]
        GRAF[ğŸ“Š Grafana]
        JAEGER[ğŸ” Jaeger]
        LOGS[ğŸ“ Loki]
    end

    USER --> CDN
    CDN --> WAF
    WAF --> LB
    LB --> KONG
    KONG --> AUTH
    KONG --> WEB
    KONG --> MOBILE
    KONG --> DESKTOP

    WEB --> MARKET_SVC
    WEB --> ANALYSIS_SVC
    WEB --> ML_SVC
    WEB --> PORTFOLIO_SVC

    MARKET_SVC --> PG
    MARKET_SVC --> TS
    MARKET_SVC --> REDIS
    MARKET_SVC --> RABBIT

    ANALYSIS_SVC --> REDIS
    ANALYSIS_SVC --> RABBIT
    
    ML_SVC --> PG
    ML_SVC --> S3
    ML_SVC --> KAFKA

    PORTFOLIO_SVC --> PG
    PORTFOLIO_SVC --> RABBIT

    MARKET --> MARKET_SVC
    NEWS --> ANALYSIS_SVC

    PROM --> GRAF
    JAEGER --> GRAF
    LOGS --> GRAF
```

## ğŸ”§ Arquitectura de Microservicios

### ğŸ“Š Market Data Service
**Responsabilidades:**
- Ingesta de datos de mercado en tiempo real
- NormalizaciÃ³n de datos de mÃºltiples fuentes
- Cache distribuido de cotizaciones
- WebSocket streams para clientes

**TecnologÃ­as:**
- FastAPI + AsyncIO para alta concurrencia
- TimescaleDB para series temporales
- Redis para cache L1
- WebSockets para streaming

```mermaid
sequenceDiagram
    participant Client
    participant MarketData
    participant Cache
    participant TimescaleDB
    participant ExternalAPI

    Client->>MarketData: GET /quotes/AAPL
    MarketData->>Cache: Check cache
    alt Cache Hit
        Cache-->>MarketData: Return cached data
    else Cache Miss
        MarketData->>TimescaleDB: Query latest data
        TimescaleDB-->>MarketData: Return data
        MarketData->>Cache: Update cache
    end
    MarketData-->>Client: Return quote
    
    par Background Process
        MarketData->>ExternalAPI: Fetch latest data
        ExternalAPI-->>MarketData: Market data
        MarketData->>TimescaleDB: Insert data
        MarketData->>Cache: Update cache
    end
```

### ğŸ” Analysis Engine
**Responsabilidades:**
- AnÃ¡lisis tÃ©cnico avanzado (RSI, MACD, Bollinger Bands)
- Procesamiento de sentiment de noticias
- CÃ¡lculo de indicadores personalizados
- Backtesting de estrategias

**PatrÃ³n de Arquitectura:** **Pipeline Pattern**

```mermaid
graph LR
    subgraph "ğŸ“¥ Data Ingestion"
        A[Market Data] --> B[Data Validator]
        C[News Data] --> B
    end
    
    subgraph "ğŸ”„ Processing Pipeline"
        B --> D[Technical Indicators]
        B --> E[Sentiment Analysis]
        D --> F[Signal Generator]
        E --> F
    end
    
    subgraph "ğŸ“¤ Output"
        F --> G[Analysis Results]
        F --> H[Event Publisher]
    end

    style D fill:#e1f5fe
    style E fill:#f3e5f5
    style F fill:#e8f5e8
```

### ğŸ¤– ML Prediction Service
**Responsabilidades:**
- Entrenamiento de modelos predictivos
- Inferencia en tiempo real
- A/B testing de modelos
- Feature engineering

**Arquitectura ML:**

```mermaid
graph TD
    subgraph "ğŸ“Š Data Pipeline"
        RAW[Raw Data] --> CLEAN[Data Cleaning]
        CLEAN --> FEAT[Feature Engineering]
        FEAT --> SPLIT[Train/Val/Test Split]
    end

    subgraph "ğŸ§  Model Training"
        SPLIT --> TRAIN[Model Training]
        TRAIN --> VAL[Validation]
        VAL --> TUNE[Hyperparameter Tuning]
        TUNE --> SELECT[Model Selection]
    end

    subgraph "ğŸš€ Deployment"
        SELECT --> STAGE[Staging Environment]
        STAGE --> AB[A/B Testing]
        AB --> PROD[Production Deployment]
    end

    subgraph "ğŸ“ˆ Monitoring"
        PROD --> DRIFT[Drift Detection]
        DRIFT --> RETRAIN[Retrain Trigger]
        RETRAIN --> TRAIN
    end

    style TRAIN fill:#bbdefb
    style PROD fill:#c8e6c9
    style DRIFT fill:#ffcdd2
```

### ğŸ’¼ Portfolio Manager
**Responsabilidades:**
- OptimizaciÃ³n de portafolios
- GestiÃ³n de riesgo
- Rebalanceo automÃ¡tico
- Reporting de performance

**PatrÃ³n:** **Strategy Pattern** para algoritmos de optimizaciÃ³n

## ğŸ—„ï¸ Arquitectura de Datos

### Modelo de Datos Principal

```mermaid
erDiagram
    USERS ||--o{ PORTFOLIOS : owns
    USERS {
        uuid id PK
        string email UK
        string password_hash
        jsonb preferences
        timestamp created_at
        timestamp updated_at
        enum status
    }

    PORTFOLIOS ||--o{ POSITIONS : contains
    PORTFOLIOS {
        uuid id PK
        uuid user_id FK
        string name
        decimal total_value
        decimal cash_balance
        jsonb allocation_target
        timestamp created_at
    }

    POSITIONS ||--|| INSTRUMENTS : references
    POSITIONS {
        uuid id PK
        uuid portfolio_id FK
        uuid instrument_id FK
        decimal quantity
        decimal avg_cost
        decimal current_value
        timestamp opened_at
    }

    INSTRUMENTS {
        uuid id PK
        string symbol UK
        string name
        enum type
        string exchange
        jsonb metadata
    }

    MARKET_DATA {
        uuid instrument_id FK
        timestamp timestamp PK
        decimal price
        decimal volume
        decimal high
        decimal low
        decimal open
    }

    PREDICTIONS {
        uuid id PK
        uuid instrument_id FK
        timestamp forecast_date
        decimal predicted_price
        decimal confidence
        string model_version
        jsonb features
    }

    TRADES {
        uuid id PK
        uuid portfolio_id FK
        uuid instrument_id FK
        enum type
        decimal quantity
        decimal price
        decimal fees
        timestamp executed_at
    }

    INSTRUMENTS ||--o{ MARKET_DATA : has
    INSTRUMENTS ||--o{ PREDICTIONS : has
    PORTFOLIOS ||--o{ TRADES : executes
```

### ğŸ“Š Particionamiento de TimescaleDB

```sql
-- Particionamiento por tiempo para market_data
CREATE TABLE market_data (
    instrument_id UUID NOT NULL,
    timestamp TIMESTAMPTZ NOT NULL,
    price DECIMAL(20,8) NOT NULL,
    volume DECIMAL(20,8),
    high DECIMAL(20,8),
    low DECIMAL(20,8),
    open DECIMAL(20,8)
);

-- Convertir a hypertable con particionamiento por tiempo
SELECT create_hypertable('market_data', 'timestamp', chunk_time_interval => INTERVAL '1 day');

-- Crear Ã­ndices optimizados
CREATE INDEX idx_market_data_instrument_time ON market_data (instrument_id, timestamp DESC);
CREATE INDEX idx_market_data_timestamp ON market_data (timestamp DESC);
```

## ğŸš¦ Patrones de ComunicaciÃ³n

### 1. **Synchronous Communication** (REST APIs)
```yaml
Pattern: Request-Response
Use Case: Client-facing APIs, real-time queries
Technology: HTTP/REST with OpenAPI specs
Timeout: 30 seconds max
```

### 2. **Asynchronous Communication** (Events)
```yaml
Pattern: Publish-Subscribe
Use Case: Inter-service communication, data updates
Technology: RabbitMQ with topic exchanges
Delivery: At-least-once with idempotency
```

### 3. **Streaming Communication** (Real-time)
```yaml
Pattern: WebSocket/Server-Sent Events
Use Case: Live market data, notifications
Technology: WebSockets with Redis pub/sub
Scaling: Horizontal with sticky sessions
```

## ğŸ” Seguridad por Capas

```mermaid
graph TD
    subgraph "ğŸ›¡ï¸ Security Layers"
        L1[ğŸŒ Network Security]
        L2[ğŸšª Authentication]
        L3[ğŸ”‘ Authorization]
        L4[ğŸ”’ Data Encryption]
        L5[ğŸ“ Audit & Monitoring]
    end

    L1 --> |TLS 1.3, WAF| L2
    L2 --> |OAuth 2.0, MFA| L3
    L3 --> |RBAC, ABAC| L4
    L4 --> |AES-256, PKI| L5
    L5 --> |SOC, SIEM| COMPLIANCE[ğŸ“‹ Compliance]

    style L1 fill:#ffebee
    style L2 fill:#e8f5e8
    style L3 fill:#e3f2fd
    style L4 fill:#fce4ec
    style L5 fill:#fff3e0
```

## ğŸ“ˆ Estrategia de Escalabilidad

### Horizontal Scaling
- **Stateless services**: Todos los microservicios son stateless
- **Load balancing**: NGINX + Kong Gateway
- **Auto-scaling**: HPA basado en CPU/memoria/custom metrics
- **Database sharding**: Particionamiento por user_id

### Vertical Scaling
- **Resource optimization**: Profiling continuo de servicios
- **Caching layers**: L1 (Redis), L2 (CDN), L3 (Application)
- **Connection pooling**: PgBouncer para PostgreSQL
- **Query optimization**: Ãndices optimizados, query analysis

## ğŸ”„ DevOps y CI/CD

```mermaid
gitGraph:
    options:
        showBranch: true
        showCommitLabel: true
    commit id: "Initial"
    branch develop
    checkout develop
    commit id: "Feature A"
    commit id: "Feature B"
    checkout main
    merge develop id: "Release v1.1"
    branch hotfix
    checkout hotfix
    commit id: "Critical Fix"
    checkout main
    merge hotfix id: "Hotfix v1.1.1"
```

### Pipeline Stages
1. **ğŸ” Code Quality**: ESLint, Prettier, SonarQube
2. **ğŸ§ª Testing**: Unit, Integration, E2E tests
3. **ğŸ”’ Security**: SAST, DAST, dependency scanning
4. **ğŸ“¦ Build**: Docker images, Helm charts
5. **ğŸš€ Deploy**: Staging â†’ Production via ArgoCD
6. **ğŸ“Š Monitor**: Synthetic tests, alerts

## ğŸ¯ SLAs y MÃ©tricas

### Service Level Objectives (SLOs)
- **Availability**: 99.9% uptime (8.77 hours downtime/year)
- **Latency**: p95 < 200ms para APIs crÃ­ticas
- **Throughput**: 10,000 requests/second sostenidas
- **Data Freshness**: Market data < 100ms delay

### Key Performance Indicators (KPIs)
- **MTTR** (Mean Time To Recovery): < 15 minutes
- **MTTD** (Mean Time To Detection): < 2 minutes
- **Error Rate**: < 0.1% para operaciones crÃ­ticas
- **Customer Satisfaction**: NPS > 70

---

**Ãšltima actualizaciÃ³n**: Enero 2026  
**VersiÃ³n**: 2.1.0