apiVersion: v1
kind: ConfigMap
metadata:
  name: alertmanager-config
  namespace: trii-monitoring
  labels:
    app.kubernetes.io/name: alertmanager
    app.kubernetes.io/component: configuration
data:
  alertmanager.yml: |
    global:
      # SMTP configuration
      smtp_smarthost: 'smtp-relay.trii.co:587'
      smtp_from: 'alerts@trii.co'
      smtp_auth_username: 'alerts@trii.co'
      smtp_auth_password: 'smtp_password_from_secret'
      smtp_require_tls: true
      
      # Slack configuration
      slack_api_url: 'https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK'
      
      # PagerDuty configuration  
      pagerduty_url: 'https://events.pagerduty.com/v2/enqueue'

    # Notification templates
    templates:
      - '/etc/alertmanager/templates/*.tmpl'

    # Routing configuration
    route:
      group_by: ['alertname', 'cluster', 'service']
      group_wait: 10s
      group_interval: 5m
      repeat_interval: 12h
      receiver: 'default-receiver'
      
      routes:
      # Critical alerts - immediate notification
      - match:
          severity: critical
        receiver: 'critical-alerts'
        group_wait: 0s
        group_interval: 1m
        repeat_interval: 5m
        
      # ML Team alerts
      - match:
          team: ml
        receiver: 'ml-team'
        group_wait: 30s
        
      # Platform team alerts  
      - match:
          team: platform
        receiver: 'platform-team'
        group_wait: 30s
        
      # Business alerts
      - match:
          team: business
        receiver: 'business-team'
        group_wait: 1m
        
      # Security alerts
      - match:
          alertname: SecurityAlert
        receiver: 'security-team'
        group_wait: 0s
        repeat_interval: 1h

    # Inhibition rules
    inhibit_rules:
    # Inhibit warning if critical is firing
    - source_match:
        severity: 'critical'
      target_match:
        severity: 'warning'
      equal: ['alertname', 'cluster', 'service']
      
    # Inhibit instance down if node down
    - source_match:
        alertname: 'NodeDown'
      target_match:
        alertname: 'InstanceDown'
      equal: ['instance']

    # Receivers configuration
    receivers:
    # Default receiver
    - name: 'default-receiver'
      email_configs:
      - to: 'alerts@trii.co'
        subject: '[TRII-{{ .GroupLabels.severity | toUpper }}] {{ .GroupLabels.alertname }}'
        body: |
          {{ range .Alerts }}
          **Alert:** {{ .Annotations.summary }}
          **Description:** {{ .Annotations.description }}
          **Severity:** {{ .Labels.severity }}
          **Service:** {{ .Labels.service }}
          **Instance:** {{ .Labels.instance }}
          **Started:** {{ .StartsAt }}
          **Dashboard:** {{ .Annotations.dashboard }}
          **Runbook:** {{ .Annotations.runbook }}
          {{ end }}

    # Critical alerts - multiple channels
    - name: 'critical-alerts'
      # Email notification
      email_configs:
      - to: 'oncall@trii.co,cto@trii.co'
        subject: 'üö® [CRITICAL] {{ .GroupLabels.alertname }} - TRII Platform'
        body: |
          üö® **CRITICAL ALERT** üö®
          
          {{ range .Alerts }}
          **Alert:** {{ .Annotations.summary }}
          **Description:** {{ .Annotations.description }}
          **Severity:** {{ .Labels.severity }}
          **Service:** {{ .Labels.service }}
          **Started:** {{ .StartsAt }}
          **Dashboard:** {{ .Annotations.dashboard }}
          **Runbook:** {{ .Annotations.runbook }}
          
          **Immediate action required!**
          {{ end }}
        
      # Slack notification
      slack_configs:
      - api_url: 'https://hooks.slack.com/services/YOUR/CRITICAL/WEBHOOK'
        channel: '#alerts-critical'
        title: 'üö® CRITICAL ALERT üö®'
        color: 'danger'
        text: |
          {{ range .Alerts }}
          **{{ .Annotations.summary }}**
          
          ‚Ä¢ **Service:** {{ .Labels.service }}
          ‚Ä¢ **Severity:** {{ .Labels.severity }}  
          ‚Ä¢ **Started:** {{ .StartsAt }}
          ‚Ä¢ **Dashboard:** <{{ .Annotations.dashboard }}|View Dashboard>
          ‚Ä¢ **Runbook:** <{{ .Annotations.runbook }}|View Runbook>
          
          {{ .Annotations.description }}
          {{ end }}
        actions:
        - type: button
          text: 'View Dashboard'
          url: '{{ (index .Alerts 0).Annotations.dashboard }}'
        - type: button  
          text: 'Acknowledge'
          url: 'https://grafana.trii.co/alerting'
          
      # PagerDuty notification
      pagerduty_configs:
      - service_key: 'your-pagerduty-integration-key'
        description: '{{ .GroupLabels.alertname }}: {{ (index .Alerts 0).Annotations.summary }}'
        severity: 'critical'
        details:
          summary: '{{ (index .Alerts 0).Annotations.summary }}'
          source: '{{ (index .Alerts 0).Labels.service }}'
          component: '{{ (index .Alerts 0).Labels.instance }}'
          group: '{{ .GroupLabels.alertname }}'

    # ML Team alerts
    - name: 'ml-team'
      email_configs:
      - to: 'ml-team@trii.co'
        subject: '[ML-{{ .GroupLabels.severity | toUpper }}] {{ .GroupLabels.alertname }}'
        body: |
          ü§ñ **ML Platform Alert**
          
          {{ range .Alerts }}
          **Alert:** {{ .Annotations.summary }}
          **Model:** {{ .Labels.model_name }}
          **Accuracy:** {{ .Labels.accuracy }}
          **Description:** {{ .Annotations.description }}
          **Started:** {{ .StartsAt }}
          {{ end }}
      
      slack_configs:
      - api_url: 'https://hooks.slack.com/services/YOUR/ML/WEBHOOK'
        channel: '#ml-alerts'
        title: 'ü§ñ ML Platform Alert'
        color: 'warning'
        text: |
          {{ range .Alerts }}
          **{{ .Annotations.summary }}**
          
          ‚Ä¢ **Model:** {{ .Labels.model_name }}
          ‚Ä¢ **Accuracy:** {{ .Labels.accuracy }}
          ‚Ä¢ **Drift Score:** {{ .Labels.drift_score }}
          ‚Ä¢ **Started:** {{ .StartsAt }}
          {{ end }}

    # Platform team alerts
    - name: 'platform-team'
      email_configs:
      - to: 'platform-team@trii.co,devops@trii.co'
        subject: '[PLATFORM-{{ .GroupLabels.severity | toUpper }}] {{ .GroupLabels.alertname }}'
        
      slack_configs:
      - api_url: 'https://hooks.slack.com/services/YOUR/PLATFORM/WEBHOOK' 
        channel: '#platform-alerts'
        title: '‚öôÔ∏è Platform Alert'
        color: '{{ if eq .Status "firing" }}warning{{ else }}good{{ end }}'

    # Business team alerts
    - name: 'business-team'
      email_configs:
      - to: 'business-team@trii.co,product@trii.co'
        subject: '[BUSINESS-{{ .GroupLabels.severity | toUpper }}] {{ .GroupLabels.alertname }}'
        body: |
          üìä **Business Metrics Alert**
          
          {{ range .Alerts }}
          **Alert:** {{ .Annotations.summary }}
          **Metric:** {{ .Labels.metric_name }}
          **Current Value:** {{ .Labels.current_value }}
          **Threshold:** {{ .Labels.threshold }}
          **Impact:** {{ .Annotations.impact }}
          **Started:** {{ .StartsAt }}
          {{ end }}
      
      slack_configs:
      - api_url: 'https://hooks.slack.com/services/YOUR/BUSINESS/WEBHOOK'
        channel: '#business-alerts'
        title: 'üìä Business Metrics Alert'
        color: 'warning'

    # Security team alerts
    - name: 'security-team'
      email_configs:
      - to: 'security@trii.co,ciso@trii.co'
        subject: 'üõ°Ô∏è [SECURITY] {{ .GroupLabels.alertname }} - Immediate Attention Required'
        body: |
          üõ°Ô∏è **SECURITY ALERT** üõ°Ô∏è
          
          {{ range .Alerts }}
          **Alert:** {{ .Annotations.summary }}
          **Severity:** {{ .Labels.severity }}
          **Source IP:** {{ .Labels.source_ip }}
          **User:** {{ .Labels.user }}
          **Action Required:** {{ .Annotations.action_required }}
          **Started:** {{ .StartsAt }}
          
          **This requires immediate security team attention!**
          {{ end }}
          
      slack_configs:
      - api_url: 'https://hooks.slack.com/services/YOUR/SECURITY/WEBHOOK'
        channel: '#security-alerts'
        title: 'üõ°Ô∏è SECURITY ALERT - IMMEDIATE ATTENTION REQUIRED'
        color: 'danger'
        text: |
          {{ range .Alerts }}
          **{{ .Annotations.summary }}**
          
          ‚Ä¢ **Severity:** {{ .Labels.severity }}
          ‚Ä¢ **Source:** {{ .Labels.source_ip }}
          ‚Ä¢ **User:** {{ .Labels.user }}
          ‚Ä¢ **Started:** {{ .StartsAt }}
          
          **{{ .Annotations.action_required }}**
          {{ end }}
          
      # Immediate PagerDuty for security
      pagerduty_configs:
      - service_key: 'security-pagerduty-key'
        description: 'SECURITY ALERT: {{ .GroupLabels.alertname }}'
        severity: 'critical'
---
apiVersion: v1
kind: Secret
metadata:
  name: monitoring-basic-auth
  namespace: trii-monitoring
  labels:
    app.kubernetes.io/name: monitoring
    app.kubernetes.io/component: basic-auth
type: Opaque
data:
  # admin:monitoring2026! - Change in production
  auth: YWRtaW46JGFwcjEkSDBHWDBkeDAkTjVuSUcuZFFQL3VuWEJwWFNlWHAzMA==